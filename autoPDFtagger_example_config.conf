; Configuration for autoPDFtagger

[DEFAULT]
language = English

[AI]
; Explicit models per task. Leave empty to skip a feature.
; Examples (via LiteLLM model routing):
; text_model_short = openai/gpt-4o
; text_model_long = openai/gpt-4o-mini
; text_threshold_words = 100
; image_model = openai/gpt-4o
; tag_model = openai/gpt-4o-mini
; Examples for other providers:
; image_model = gemini/gemini-1.5-pro
; image_model = ollama/llava   ; requires a local Ollama with llava pulled
text_model_short = openai/gpt-5-nano
text_model_long = openai/gpt-5-nano
text_threshold_words = 100
; Temperature 1.0 required for GPT-5 models
text_temperature = 1
image_model = openai/gpt-5-nano
tag_model = openai/gpt-5-nano
; Optional vision sampling temperature (0.0â€“1.0)
image_temperature = 1
; Optional artificial latency (ms) for TEST/* mock models to simulate API time
; test_mock_sleep_ms = 0

[OCR]
; Enable OCR before text analysis. Accepted values: auto, true, false
enabled = auto
; Tesseract language codes, separated by + (example: deu+eng)
languages = eng+deu

[JOBS]
; Concurrency controls for local OCR (per-doc) and AI tasks (combined)
; Defaults: OCR = CPU cores, AI = 4
ocr_max_workers = 2
ai_max_workers = 4
; Interval for periodic status summaries in seconds
status_interval_sec = 2.0

[OPENAI-API]
; Optional fallback if environment variable OPENAI_API_KEY is not set
; API-Key = sk-...
