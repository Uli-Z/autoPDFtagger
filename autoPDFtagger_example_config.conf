; Configuration for autoPDFtagger

[DEFAULT]
language = English

[AI]
; Explicit models per task. Leave empty to skip a feature.
; Examples (via LiteLLM model routing):
; text_model_short = openai/gpt-4o
; text_model_long = openai/gpt-4o-mini
; text_threshold_words = 100
; image_model = openai/gpt-4o
; tag_model = openai/gpt-4o-mini
; Examples for other providers:
; image_model = gemini/gemini-1.5-pro
; image_model = ollama/llava   ; requires a local Ollama with llava pulled
text_model_short = openai/gpt-5-mini
text_model_long = openai/gpt-5-nano
text_threshold_words = 100
; Temperature 1.0 required for GPT-5 models
text_temperature = 1
image_model = openai/gpt-5-nano
tag_model = openai/gpt-5-nano
; Optional vision sampling temperature (0.0â€“1.0)
image_temperature = 1
; Combined analysis model (text + images together). Defaults to image_model when empty
combined_model = openai/gpt-5-nano
; Temperature for combined analysis
combined_temperature = 1
; Maximum characters of text context per page (0 = unlimited)
combined_text_max_chars = 0
; Token budgeting for combined requests
combined_token_limit = 1000000
combined_tokens_per_image = 4000
; Image selection rules
combined_priority_first_pages = 3
combined_small_image_min_edge_cm = 3.0
combined_page_group_threshold = 3
; Exclude small icons/very small images in combined mode
combined_exclude_small_icons = true
; Optional artificial latency (ms) for TEST/* mock models to simulate API time
; test_mock_sleep_ms = 0


; Image selection and prioritization controls
; Maximum number of images (or rendered pages) analyzed per PDF
max_images_per_pdf = 3
; A page is treated as a scan if the largest image covers at least this fraction of the page area
scan_coverage_threshold = 0.95
; Pages with indices < this number receive top priority (1-based: pages 1..N)
first_pages_priority = 3
; Images smaller than this minimum edge length (in cm) are considered icons
min_icon_edge_cm = 2.0
; If a page contains many small images/icons, group them by uploading a full-page render instead
group_small_images_per_page = true
; Minimum count of small images on a page to trigger grouping
small_images_group_threshold = 3
; Maximum rendered page dimension in pixels when grouping or scanning (longest edge)
page_render_max_px = 1536
; Maximum rendered dimension for single-image regions (xref), defaults to page_render_max_px
image_render_max_px = 1536
; Exclude small icons from per-image candidates
exclude_small_icons = true
; Maximum characters of page-local text context attached per image in the prompt
image_context_max_chars = 800
; Vector fallback: if no images are found and a page has very few words, render the page instead
vector_fallback_words_threshold = 15
vector_fallback_max_pages = 2

[OCR]
; Enable OCR before text analysis. Accepted values: auto, true, false
enabled = auto
; Tesseract language codes, separated by + (example: deu+eng)
languages = eng+deu

[JOBS]
; Concurrency controls for local OCR (per-doc) and AI tasks (combined)
; Defaults: OCR = CPU cores, AI = 4
ocr_max_workers = 2
ai_max_workers = 4
; Interval for periodic status summaries in seconds
status_interval_sec = 2.0

[CACHE]
; Enable persistent cache for OCR pages and AI requests
enabled = true
; Time to live in seconds (default 24h)
ttl_seconds = 86400
; Optional custom cache directory (defaults to ~/.autoPDFtagger/cache)
; dir = /path/to/cache

[EXPORT]
; Filename scheme for exported copies (uses strftime + placeholders)
; Allowed placeholders: {TITLE}, {CREATOR}; date uses Python strftime codes
; Examples:
; filename_format = %Y-%m-%d-{TITLE}.pdf
; filename_format = %Y%m%d-{CREATOR}-{TITLE}.pdf
filename_format = %Y-%m-%d-{CREATOR}-{TITLE}.pdf

[OPENAI-API]
; Optional fallback if environment variable OPENAI_API_KEY is not set
; API-Key = sk-...

; Optional pricing overrides (used when provider does not return costs)
; [PRICING]
; Example: set flat per-image cost for a model or provider/base
; openai/gpt-4o.image_flat = 0.005
; openai/gpt-4o-mini.image_flat = 0.0015
; You can also override token rates via:
; openai/gpt-4o.input_per_1k = 0.005
; openai/gpt-4o.output_per_1k = 0.015
